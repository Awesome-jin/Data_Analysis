{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타이타닉 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "survived       891 non-null int64\n",
      "pclass         891 non-null int64\n",
      "sex            891 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          891 non-null int64\n",
      "parch          891 non-null int64\n",
      "fare           891 non-null float64\n",
      "embarked       889 non-null object\n",
      "class          891 non-null category\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null bool\n",
      "deck           203 non-null category\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null bool\n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n",
      "\n",
      "   survived  pclass    sex    age  sibsp  parch   fare  embarked  class  \\\n",
      "0     False   False  False  False  False  False  False     False  False   \n",
      "1     False   False  False  False  False  False  False     False  False   \n",
      "2     False   False  False  False  False  False  False     False  False   \n",
      "3     False   False  False  False  False  False  False     False  False   \n",
      "4     False   False  False  False  False  False  False     False  False   \n",
      "5     False   False  False   True  False  False  False     False  False   \n",
      "6     False   False  False  False  False  False  False     False  False   \n",
      "7     False   False  False  False  False  False  False     False  False   \n",
      "8     False   False  False  False  False  False  False     False  False   \n",
      "9     False   False  False  False  False  False  False     False  False   \n",
      "\n",
      "     who  adult_male   deck  embark_town  alive  alone  \n",
      "0  False       False   True        False  False  False  \n",
      "1  False       False  False        False  False  False  \n",
      "2  False       False   True        False  False  False  \n",
      "3  False       False  False        False  False  False  \n",
      "4  False       False   True        False  False  False  \n",
      "5  False       False   True        False  False  False  \n",
      "6  False       False  False        False  False  False  \n",
      "7  False       False   True        False  False  False  \n",
      "8  False       False   True        False  False  False  \n",
      "9  False       False   True        False  False  False  \n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "survived       891 non-null int64\n",
      "pclass         891 non-null int64\n",
      "sex            891 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          891 non-null int64\n",
      "parch          891 non-null int64\n",
      "fare           891 non-null float64\n",
      "embarked       889 non-null object\n",
      "class          891 non-null category\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null bool\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null bool\n",
      "dtypes: bool(2), category(1), float64(2), int64(4), object(5)\n",
      "memory usage: 79.4+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 714 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "survived       714 non-null int64\n",
      "pclass         714 non-null int64\n",
      "sex            714 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          714 non-null int64\n",
      "parch          714 non-null int64\n",
      "fare           714 non-null float64\n",
      "embarked       712 non-null object\n",
      "class          714 non-null category\n",
      "who            714 non-null object\n",
      "adult_male     714 non-null bool\n",
      "embark_town    712 non-null object\n",
      "alive          714 non-null object\n",
      "alone          714 non-null bool\n",
      "dtypes: bool(2), category(1), float64(2), int64(4), object(5)\n",
      "memory usage: 69.1+ KB\n",
      "None\n",
      "\n",
      "820      S\n",
      "821      S\n",
      "822      S\n",
      "823      S\n",
      "824      S\n",
      "825      Q\n",
      "826      S\n",
      "827      C\n",
      "828      Q\n",
      "829    NaN\n",
      "Name: embarked, dtype: object\n",
      "\n",
      "820    S\n",
      "821    S\n",
      "822    S\n",
      "823    S\n",
      "824    S\n",
      "825    Q\n",
      "826    S\n",
      "827    C\n",
      "828    Q\n",
      "829    Q\n",
      "Name: embarked, dtype: object\n",
      "[[100.]\n",
      " [200.]\n",
      " [300.]\n",
      " [500.]\n",
      " [275.]]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fancyimpute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-09d579e529e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m#4. KNN(군집) 알고리즘을 이용한 결측치 채우기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfancyimpute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;31m# fancyimpute 없으면 설치하고 오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mfeatures2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m105\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fancyimpute'"
     ]
    }
   ],
   "source": [
    "#필요한 패키지들 가져오기 \n",
    "import numpy as np #수치연산, 선형대수, ndarray라는 자료 구조를 가진 패키지\n",
    "import pandas as pd #Series, DF 자료구조를 가ㅣㄴ 패키지\n",
    "import seaborn as sns #샘플데이터와 시각화\n",
    "\n",
    "#1. 타이타닉 데이터 seaborn 패키지 명령어로 가져오기\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.info()\n",
    "print(\"\")\n",
    "\n",
    "#2. NaN을 소유하고 있는지 확인하기\n",
    "#2-1. 앞의 10개의 데이터가 NaN을 포함하는지 확인\n",
    "print(titanic.head(10).isnull())\n",
    "print(\"\")\n",
    "\n",
    "#2-2 NaN을 포함한 행의 개수를 파악하기\n",
    "print(titanic.isnull().sum()) #열로 파악하고 싶다면 sum(axis=1)\n",
    "print(\"\")\n",
    "\n",
    "#NaN가 25% 이상인 열은 제거하겠다.\n",
    "titanic.dropna(thresh=(len(titanic)/4), axis=1, inplace=True)\n",
    "print(titanic.info())\n",
    "print(\"\")\n",
    "\n",
    "#2-3. age열의 값이 NaN인 행을 제거\n",
    "titanic.dropna(subset=['age'], how='any', axis=0, inplace=True)\n",
    "print(titanic.info())\n",
    "print(\"\")\n",
    "\n",
    "#3. 삭제 대신 치환으로 작업해보기 \n",
    "titanic = sns.load_dataset('titanic')\n",
    "print(titanic['embarked'][820:830])\n",
    "print(\"\")\n",
    "\n",
    "#3-1. 앞의 값으로 NaN값을 채워보기\n",
    "titanic['embarked'].fillna(method='ffill', inplace=True)\n",
    "print(titanic['embarked'][820:830])\n",
    "# 셀 병합이 된 경우에 사용 할 수 있음\n",
    "\n",
    "#3-2. 사이킷런으로 결측 값 채워보기\n",
    "features = np.array([[100],[200],[300],[500],[np.NaN]])\n",
    "\n",
    "#3-3. 평균으로 채워주는 Imputer를 만들어보자\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean') #mean대신 mode나 median도 사용 가능\n",
    "\n",
    "#3-4. 3-2에서 만든 features에 imputer를 넣어보자\n",
    "features_imputed = imputer.fit_transform(features)\n",
    "print(features_imputed) #상단에서 NaN으로 만든 값이 평균 값으로 치환된 걸 확인 가능\n",
    "\n",
    "#4. KNN(군집) 알고리즘을 이용한 결측치 채우기\n",
    "from fancyimpute import KNN\n",
    "# fancyimpute 없으면 설치하고 오기\n",
    "features2 = np.array([200,300],[100,200],[300,400],[400,500],[300,200],[105,np.NaN])\n",
    "features2_imputed = KNN(k=5, verbose=0).fit_transform(featrues2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>두산</td>\n",
       "      <td>서울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SK</td>\n",
       "      <td>인천</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>롯데</td>\n",
       "      <td>부산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>삼성</td>\n",
       "      <td>대구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>한화</td>\n",
       "      <td>대전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>NC</td>\n",
       "      <td>창원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>기아</td>\n",
       "      <td>광주</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  두산  서울\n",
       "1  SK  인천\n",
       "3  롯데  부산\n",
       "4  삼성  대구\n",
       "5  한화  대전\n",
       "6  NC  창원\n",
       "7  기아  광주"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 데이터 처리 하기\n",
    "df = pd.DataFrame([['두산','SK','두산','롯데','삼성','한화','NC','기아'],['서울','인천','서울','부산','대구','대전','창원','광주']])\n",
    "df=df.T #행과 열을 뒤바꾸기 (행단위로 비교하기 때문)\n",
    "\n",
    "#1. 중복 데이터를 먼저 확인한다\n",
    "df.duplicated()\n",
    "\n",
    "#2. 중복 데이터 제거해버리기\n",
    "df.drop_duplicates(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자료형 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      "mpg             398 non-null float64\n",
      "cylinder        398 non-null int64\n",
      "displacement    398 non-null float64\n",
      "horsepower      398 non-null object\n",
      "weight          398 non-null float64\n",
      "acceleration    398 non-null float64\n",
      "year            398 non-null int64\n",
      "origin          398 non-null int64\n",
      "name            398 non-null object\n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 28.1+ KB\n",
      "None\n",
      "    mpg  cylinder  displacement horsepower  weight  acceleration  year  \\\n",
      "0  18.0         8         307.0      130.0  3504.0          12.0    70   \n",
      "1  15.0         8         350.0      165.0  3693.0          11.5    70   \n",
      "2  18.0         8         318.0      150.0  3436.0          11.0    70   \n",
      "3  16.0         8         304.0      150.0  3433.0          12.0    70   \n",
      "4  17.0         8         302.0      140.0  3449.0          10.5    70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      "mpg             398 non-null float64\n",
      "cylinder        398 non-null int64\n",
      "displacement    398 non-null float64\n",
      "horsepower      398 non-null object\n",
      "weight          398 non-null float64\n",
      "acceleration    398 non-null float64\n",
      "year            398 non-null int64\n",
      "origin          398 non-null category\n",
      "name            398 non-null object\n",
      "dtypes: category(1), float64(4), int64(2), object(2)\n",
      "memory usage: 25.5+ KB\n",
      "None\n",
      "\n",
      "[ 68.   164.75 261.5  358.25 455.  ]\n",
      "displacement  소형  중형  대형  초대형\n",
      "0              0   0   1    0\n",
      "1              0   0   1    0\n",
      "2              0   0   1    0\n",
      "3              0   0   1    0\n",
      "4              0   0   1    0\n",
      "..            ..  ..  ..  ...\n",
      "393            1   0   0    0\n",
      "394            1   0   0    0\n",
      "395            1   0   0    0\n",
      "396            1   0   0    0\n",
      "397            1   0   0    0\n",
      "\n",
      "[398 rows x 4 columns]\n",
      "[[1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#1. auto-mpg_1.csv 파일 불러오기\n",
    "df = pd.read_csv('./data/auto-mpg_1.csv', header=None) #기존 자료에 헤더가 없거나 바꾸고자 하는 경우 사용 가능한 옵션\n",
    "df.columns = ['mpg', 'cylinder', 'displacement','horsepower','weight','acceleration','year','origin','name']\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(\"\")\n",
    "\n",
    "#2. origin의 값 바꿔보기\n",
    "# 1 => 미국, 2 => 유럽, 3 => 일본 으로 치환하고 자료타입을 int64 > object로 바꾸어보자\n",
    "\n",
    "df['origin'].replace({1:'USA', 2:'EU', 3:'JPN'}, inplace=True)\n",
    "df['origin'] = df['origin'].astype('category')\n",
    "#df['origin'] = df['origin'].astype('str')  #다시 문자열로 바꾸고 싶다면 str으로. \n",
    "print(df.info())\n",
    "print(\"\")\n",
    "\n",
    "#3. Continuous to Discrete\n",
    "# >> displacement를 대형, 중형, 소형으로 바꾸어보자!\n",
    "\n",
    "#3-1. 3등분 할 숫자 배열을 만들어 준다.\n",
    "count, bin_dividers = np.histogram(df['displacement'],bins=4) \n",
    "print(bin_dividers)\n",
    "#bins가 3이면 최소값 ~ 최대값 까지 interval이 3개다. 즉 점은 4개가 필요하다(names와 개수를 맞춘다 생각하자).\n",
    "\n",
    "#3-2 치환할 데이터를 만들어준다\n",
    "bin_names = ['소형','중형','대형','초대형']\n",
    "\n",
    "#3-3 치환 (구간분할 하기)\n",
    "df['displacement'] = pd.cut(x = df['displacement'], bins=bin_dividers, labels=bin_names, include_lowest=True)\n",
    "df\n",
    "\n",
    "dummy=pd.get_dummies(df['displacement']) #get_dumiies()라는 함수를 이용해 원핫 인코딩을 하면 컬럼에 나올 수 있는 모든 값을 조사해서 가능하면 1. 없으면 0.\n",
    "print(dummy)\n",
    "\n",
    "\n",
    "#4. Numpy의 digitize를 이용한 변환\n",
    "age = np.array([[30],[40],[29],[50],[29],[31]])\n",
    "print(np.digitize(age,bins=[30, 40])) #0~30, 30~40, 40~ 으로 구간을 나누어 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 개의 열로 구성된 데이터의 이산화 - KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1  group\n",
       "0  20  30      0\n",
       "1  30  50      1\n",
       "2  50  70      2\n",
       "3  40  20      0\n",
       "4  23  14      0\n",
       "5  30  42      1\n",
       "6  30  64      1\n",
       "7  64  42      2"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = np.array([[20,30],[30,50],[50,70],[40,20],[23,14],[30,42],[30,64],[64,42]])\n",
    "df = pd.DataFrame(sample)\n",
    "df\n",
    "\n",
    "#1. KMeans 군집분석을 위한 라이브러리 불러오기\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#1-1. 군집분석 알고리즘이 들어간 객체를 생성\n",
    "cluster = KMeans(3, random_state=0) \n",
    "\n",
    "#1-2. 데이터를 가지고 fit(훈련)을 시킴\n",
    "cluster.fit(sample)\n",
    "\n",
    "#1-3. 예측한 군집 결과를 데이터프레임에 그룹 열로 할당\n",
    "df['group'] = cluster.predict(sample)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷 런을 이용한 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0]\n",
      " [0 0 1 1 0]\n",
      " [1 0 0 0 1]\n",
      " [0 0 0 1 1]]\n",
      "['c#' 'c++' 'java' 'python' 'r']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'displacement'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'displacement'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-1d64fcbbf808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'displacement'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'displacement'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "one_hot = LabelBinarizer()\n",
    "#print(one_hot.fit_transform(df['displacement'])) \n",
    "\n",
    "#데이터를 정렬하기 때문에 순서를 확인\n",
    "#print(one_hot.classes_)\n",
    "#print(one_hot.inverse_transform(one_hot.fit_transform(df['displacement'])))\n",
    "\n",
    "#여러 개의 특성을 원핫 인코딩\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "features = [('java','c++'),('java','python'),('c#','r'),('python','r')]\n",
    "one_hot = MultiLabelBinarizer()\n",
    "print(one_hot.fit_transform(features))\n",
    "print(one_hot.classes_)\n",
    "\n",
    "\n",
    "#get_dummies는 하나의 특성을 하나의 컬럼으로 생성\n",
    "#값의 종류가 15가지이면 15개의 컬럼을 생성\n",
    "# (solution) 컬럼은 1개만 만들고 0부터 일련번호 형태로 값을 설정\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "one_hot = LabelEncoder()\n",
    "print(one_hot.fit_transform(df['displacement']))\n",
    "print(one_hot.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순서가 있는 범주형 데이터 인코딩 - Ordinal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score\n",
      "0     A\n",
      "1     B\n",
      "2     C\n",
      "3     D\n",
      "4     F\n",
      "  Score  encoder\n",
      "0     A      4.0\n",
      "1     B      3.0\n",
      "2     C      2.0\n",
      "3     D      1.0\n",
      "4     F      0.0\n",
      "[[3. 0.]\n",
      " [2. 2.]\n",
      " [0. 1.]\n",
      " [1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "#sklearn의 인코더들은 문자열을 기준으로 정렬을 한 후 수치를 부여. 원하는 수치값을 부여하는 것은 불가능\n",
    "#범주형 데이터에 원하는 수치값을 부여해서 인코딩 할 때는 replace 메소드나 OrdinalEncoder를 이용\n",
    "df = pd.DataFrame({\"Score\":['A','B','C','D','F']})\n",
    "print(df)\n",
    "\n",
    "#A:4.0, #B:3.0 #C:2.0 #D:1.0 #F : 0\n",
    "mapper = {'A':4.0,'B':3.0,'C':2.0,'D':1.0,'F':0}\n",
    "\n",
    "df['encoder'] = df['Score'].replace(mapper)\n",
    "print(df)\n",
    "\n",
    "\n",
    "#순서가 있는 범주형 인코딩\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "features = np.array([['서울',2],['부산',52],['경기',31],['대구',54]])\n",
    "\n",
    "#1. 객체를 생성하자\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "#2.객체에다가 데이터를 준다\n",
    "result = encoder.fit_transform(features)\n",
    "print(result) #1열은 가나다순 정렬. 2열은 숫자 정렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 데이터에서 누락값 삭제 - 머신러닝 알고리즘 이용_최근이웃법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.K평균분류 패키지 import\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#훈련할 데이터 생성\n",
    "X = np.array([[0, 2.10, 14.1],[1,1.18,13.33],[0, 1.22,1.27],[1,-0.10,-14.45]])\n",
    "\n",
    "#NaN을 가진 데이터\n",
    "X_with_nan = np.array([[np.NaN,0.87,13.31],[np.NaN, -0.67, -0.22]])\n",
    "\n",
    "#2. 분류기를 생성 \n",
    "clf = KNeighborsClassifier(3,weights='distance')\n",
    "\n",
    "#3. 훈련할 데이터 할당 : 1번째 이후 전체 데이터를 가지고 0번째 데이터를 예측\n",
    "train_model = clf.fit(X[:,1:],X[:,0])\n",
    "\n",
    "#4. 데이터 예측\n",
    "imputed_values = train_model.predict(X_with_nan[:,1:]) #X_with_nan에 행 전체에 1열 이후로 값들을 기반으로 예측해라 \n",
    "imputed_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
