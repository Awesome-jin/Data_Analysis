{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타이타닉 데이터 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      "survived       891 non-null int64\n",
      "pclass         891 non-null int64\n",
      "sex            891 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          891 non-null int64\n",
      "parch          891 non-null int64\n",
      "fare           891 non-null float64\n",
      "embarked       889 non-null object\n",
      "class          891 non-null category\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null bool\n",
      "deck           203 non-null category\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null bool\n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n",
      "\n",
      "   survived  pclass    sex    age  sibsp  parch   fare  embarked  class  \\\n",
      "0     False   False  False  False  False  False  False     False  False   \n",
      "1     False   False  False  False  False  False  False     False  False   \n",
      "2     False   False  False  False  False  False  False     False  False   \n",
      "3     False   False  False  False  False  False  False     False  False   \n",
      "4     False   False  False  False  False  False  False     False  False   \n",
      "5     False   False  False   True  False  False  False     False  False   \n",
      "6     False   False  False  False  False  False  False     False  False   \n",
      "7     False   False  False  False  False  False  False     False  False   \n",
      "8     False   False  False  False  False  False  False     False  False   \n",
      "9     False   False  False  False  False  False  False     False  False   \n",
      "\n",
      "     who  adult_male   deck  embark_town  alive  alone  \n",
      "0  False       False   True        False  False  False  \n",
      "1  False       False  False        False  False  False  \n",
      "2  False       False   True        False  False  False  \n",
      "3  False       False  False        False  False  False  \n",
      "4  False       False   True        False  False  False  \n",
      "5  False       False   True        False  False  False  \n",
      "6  False       False  False        False  False  False  \n",
      "7  False       False   True        False  False  False  \n",
      "8  False       False   True        False  False  False  \n",
      "9  False       False   True        False  False  False  \n",
      "\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "survived       891 non-null int64\n",
      "pclass         891 non-null int64\n",
      "sex            891 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          891 non-null int64\n",
      "parch          891 non-null int64\n",
      "fare           891 non-null float64\n",
      "embarked       889 non-null object\n",
      "class          891 non-null category\n",
      "who            891 non-null object\n",
      "adult_male     891 non-null bool\n",
      "embark_town    889 non-null object\n",
      "alive          891 non-null object\n",
      "alone          891 non-null bool\n",
      "dtypes: bool(2), category(1), float64(2), int64(4), object(5)\n",
      "memory usage: 79.4+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 714 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      "survived       714 non-null int64\n",
      "pclass         714 non-null int64\n",
      "sex            714 non-null object\n",
      "age            714 non-null float64\n",
      "sibsp          714 non-null int64\n",
      "parch          714 non-null int64\n",
      "fare           714 non-null float64\n",
      "embarked       712 non-null object\n",
      "class          714 non-null category\n",
      "who            714 non-null object\n",
      "adult_male     714 non-null bool\n",
      "embark_town    712 non-null object\n",
      "alive          714 non-null object\n",
      "alone          714 non-null bool\n",
      "dtypes: bool(2), category(1), float64(2), int64(4), object(5)\n",
      "memory usage: 69.1+ KB\n",
      "None\n",
      "\n",
      "820      S\n",
      "821      S\n",
      "822      S\n",
      "823      S\n",
      "824      S\n",
      "825      Q\n",
      "826      S\n",
      "827      C\n",
      "828      Q\n",
      "829    NaN\n",
      "Name: embarked, dtype: object\n",
      "\n",
      "820    S\n",
      "821    S\n",
      "822    S\n",
      "823    S\n",
      "824    S\n",
      "825    Q\n",
      "826    S\n",
      "827    C\n",
      "828    Q\n",
      "829    Q\n",
      "Name: embarked, dtype: object\n",
      "[[100.]\n",
      " [200.]\n",
      " [300.]\n",
      " [500.]\n",
      " [275.]]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fancyimpute'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-09d579e529e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m#4. KNN(군집) 알고리즘을 이용한 결측치 채우기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfancyimpute\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;31m# fancyimpute 없으면 설치하고 오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mfeatures2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m105\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fancyimpute'"
     ]
    }
   ],
   "source": [
    "#필요한 패키지들 가져오기 \n",
    "import numpy as np #수치연산, 선형대수, ndarray라는 자료 구조를 가진 패키지\n",
    "import pandas as pd #Series, DF 자료구조를 가 패키지\n",
    "import seaborn as sns #샘플데이터와 시각화\n",
    "\n",
    "#1. 타이타닉 데이터 seaborn 패키지 명령어로 가져오기\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic.info()\n",
    "print(\"\")\n",
    "\n",
    "#2. NaN을 소유하고 있는지 확인하기\n",
    "#2-1. 앞의 10개의 데이터가 NaN을 포함하는지 확인\n",
    "print(titanic.head(10).isnull())\n",
    "print(\"\")\n",
    "\n",
    "#2-2 NaN을 포함한 행의 개수를 파악하기\n",
    "print(titanic.isnull().sum()) #열로 파악하고 싶다면 sum(axis=1)\n",
    "print(\"\")\n",
    "\n",
    "#NaN가 25% 이상인 열은 제거하겠다.\n",
    "titanic.dropna(thresh=(len(titanic)/4), axis=1, inplace=True)\n",
    "print(titanic.info())\n",
    "print(\"\")\n",
    "\n",
    "#2-3. age열의 값이 NaN인 행을 제거\n",
    "titanic.dropna(subset=['age'], how='any', axis=0, inplace=True)\n",
    "print(titanic.info())\n",
    "print(\"\")\n",
    "\n",
    "#3. 삭제 대신 치환으로 작업해보기 \n",
    "titanic = sns.load_dataset('titanic')\n",
    "print(titanic['embarked'][820:830])\n",
    "print(\"\")\n",
    "\n",
    "#3-1. 앞의 값으로 NaN값을 채워보기\n",
    "titanic['embarked'].fillna(method='ffill', inplace=True)\n",
    "print(titanic['embarked'][820:830])\n",
    "# 셀 병합이 된 경우에 사용 할 수 있음\n",
    "\n",
    "#3-2. 사이킷런으로 결측 값 채워보기\n",
    "features = np.array([[100],[200],[300],[500],[np.NaN]])\n",
    "\n",
    "#3-3. 평균으로 채워주는 Imputer를 만들어보자\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean') #mean대신 mode나 median도 사용 가능\n",
    "\n",
    "#3-4. 3-2에서 만든 features에 imputer를 넣어보자\n",
    "features_imputed = imputer.fit_transform(features)\n",
    "print(features_imputed) #상단에서 NaN으로 만든 값이 평균 값으로 치환된 걸 확인 가능\n",
    "\n",
    "#4. KNN(군집) 알고리즘을 이용한 결측치 채우기\n",
    "from fancyimpute import KNN\n",
    "# fancyimpute 없으면 설치하고 오기\n",
    "features2 = np.array([200,300],[100,200],[300,400],[400,500],[300,200],[105,np.NaN])\n",
    "features2_imputed = KNN(k=5, verbose=0).fit_transform(featrues2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 중복데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>두산</td>\n",
       "      <td>서울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SK</td>\n",
       "      <td>인천</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>롯데</td>\n",
       "      <td>부산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>삼성</td>\n",
       "      <td>대구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>한화</td>\n",
       "      <td>대전</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>NC</td>\n",
       "      <td>창원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>기아</td>\n",
       "      <td>광주</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0  두산  서울\n",
       "1  SK  인천\n",
       "3  롯데  부산\n",
       "4  삼성  대구\n",
       "5  한화  대전\n",
       "6  NC  창원\n",
       "7  기아  광주"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 데이터 처리 하기\n",
    "df = pd.DataFrame([['두산','SK','두산','롯데','삼성','한화','NC','기아'],['서울','인천','서울','부산','대구','대전','창원','광주']])\n",
    "df=df.T #행과 열을 뒤바꾸기 (행단위로 비교하기 때문)\n",
    "\n",
    "#1. 중복 데이터를 먼저 확인한다\n",
    "df.duplicated()\n",
    "\n",
    "#2. 중복 데이터 제거해버리기\n",
    "df.drop_duplicates(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자료형 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      "mpg             398 non-null float64\n",
      "cylinder        398 non-null int64\n",
      "displacement    398 non-null float64\n",
      "horsepower      398 non-null object\n",
      "weight          398 non-null float64\n",
      "acceleration    398 non-null float64\n",
      "year            398 non-null int64\n",
      "origin          398 non-null int64\n",
      "name            398 non-null object\n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 28.1+ KB\n",
      "None\n",
      "    mpg  cylinder  displacement horsepower  weight  acceleration  year  \\\n",
      "0  18.0         8         307.0      130.0  3504.0          12.0    70   \n",
      "1  15.0         8         350.0      165.0  3693.0          11.5    70   \n",
      "2  18.0         8         318.0      150.0  3436.0          11.0    70   \n",
      "3  16.0         8         304.0      150.0  3433.0          12.0    70   \n",
      "4  17.0         8         302.0      140.0  3449.0          10.5    70   \n",
      "\n",
      "   origin                       name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      "mpg             398 non-null float64\n",
      "cylinder        398 non-null int64\n",
      "displacement    398 non-null float64\n",
      "horsepower      398 non-null object\n",
      "weight          398 non-null float64\n",
      "acceleration    398 non-null float64\n",
      "year            398 non-null int64\n",
      "origin          398 non-null category\n",
      "name            398 non-null object\n",
      "dtypes: category(1), float64(4), int64(2), object(2)\n",
      "memory usage: 25.5+ KB\n",
      "None\n",
      "\n",
      "[ 68.   164.75 261.5  358.25 455.  ]\n",
      "displacement  소형  중형  대형  초대형\n",
      "0              0   0   1    0\n",
      "1              0   0   1    0\n",
      "2              0   0   1    0\n",
      "3              0   0   1    0\n",
      "4              0   0   1    0\n",
      "..            ..  ..  ..  ...\n",
      "393            1   0   0    0\n",
      "394            1   0   0    0\n",
      "395            1   0   0    0\n",
      "396            1   0   0    0\n",
      "397            1   0   0    0\n",
      "\n",
      "[398 rows x 4 columns]\n",
      "[[1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#1. auto-mpg_1.csv 파일 불러오기\n",
    "df = pd.read_csv('./data/auto-mpg_1.csv', header=None) #기존 자료에 헤더가 없거나 바꾸고자 하는 경우 사용 가능한 옵션\n",
    "df.columns = ['mpg', 'cylinder', 'displacement','horsepower','weight','acceleration','year','origin','name']\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(\"\")\n",
    "\n",
    "#2. origin의 값 바꿔보기\n",
    "# 1 => 미국, 2 => 유럽, 3 => 일본 으로 치환하고 자료타입을 int64 > object로 바꾸어보자\n",
    "\n",
    "df['origin'].replace({1:'USA', 2:'EU', 3:'JPN'}, inplace=True)\n",
    "df['origin'] = df['origin'].astype('category')\n",
    "#df['origin'] = df['origin'].astype('str')  #다시 문자열로 바꾸고 싶다면 str으로. \n",
    "print(df.info())\n",
    "print(\"\")\n",
    "\n",
    "#3. Continuous to Discrete\n",
    "# >> displacement를 대형, 중형, 소형으로 바꾸어보자!\n",
    "\n",
    "#3-1. 3등분 할 숫자 배열을 만들어 준다.\n",
    "count, bin_dividers = np.histogram(df['displacement'],bins=4) \n",
    "print(bin_dividers)\n",
    "#bins가 3이면 최소값 ~ 최대값 까지 interval이 3개다. 즉 점은 4개가 필요하다(names와 개수를 맞춘다 생각하자).\n",
    "\n",
    "#3-2 치환할 데이터를 만들어준다\n",
    "bin_names = ['소형','중형','대형','초대형']\n",
    "\n",
    "#3-3 치환 (구간분할 하기)\n",
    "df['displacement'] = pd.cut(x = df['displacement'], bins=bin_dividers, labels=bin_names, include_lowest=True)\n",
    "df\n",
    "\n",
    "dummy=pd.get_dummies(df['displacement']) #get_dumiies()라는 함수를 이용해 원핫 인코딩을 하면 컬럼에 나올 수 있는 모든 값을 조사해서 가능하면 1. 없으면 0.\n",
    "print(dummy)\n",
    "\n",
    "\n",
    "#4. Numpy의 digitize를 이용한 변환\n",
    "age = np.array([[30],[40],[29],[50],[29],[31]])\n",
    "print(np.digitize(age,bins=[30, 40])) #0~30, 30~40, 40~ 으로 구간을 나누어 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 개의 열로 구성된 데이터의 이산화 - KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1  group\n",
       "0  20  30      0\n",
       "1  30  50      1\n",
       "2  50  70      2\n",
       "3  40  20      0\n",
       "4  23  14      0\n",
       "5  30  42      1\n",
       "6  30  64      1\n",
       "7  64  42      2"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = np.array([[20,30],[30,50],[50,70],[40,20],[23,14],[30,42],[30,64],[64,42]])\n",
    "df = pd.DataFrame(sample)\n",
    "df\n",
    "\n",
    "#1. KMeans 군집분석을 위한 라이브러리 불러오기\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#1-1. 군집분석 알고리즘이 들어간 객체를 생성\n",
    "cluster = KMeans(3, random_state=0) \n",
    "\n",
    "#1-2. 데이터를 가지고 fit(훈련)을 시킴\n",
    "cluster.fit(sample)\n",
    "\n",
    "#1-3. 예측한 군집 결과를 데이터프레임에 그룹 열로 할당\n",
    "df['group'] = cluster.predict(sample)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사이킷 런을 이용한 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0]\n",
      " [0 0 1 1 0]\n",
      " [1 0 0 0 1]\n",
      " [0 0 0 1 1]]\n",
      "['c#' 'c++' 'java' 'python' 'r']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'displacement'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'displacement'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-1d64fcbbf808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'displacement'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'displacement'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "one_hot = LabelBinarizer()\n",
    "#print(one_hot.fit_transform(df['displacement'])) \n",
    "\n",
    "#데이터를 정렬하기 때문에 순서를 확인\n",
    "#print(one_hot.classes_)\n",
    "#print(one_hot.inverse_transform(one_hot.fit_transform(df['displacement'])))\n",
    "\n",
    "#여러 개의 특성을 원핫 인코딩\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "features = [('java','c++'),('java','python'),('c#','r'),('python','r')]\n",
    "one_hot = MultiLabelBinarizer()\n",
    "print(one_hot.fit_transform(features))\n",
    "print(one_hot.classes_)\n",
    "\n",
    "\n",
    "#get_dummies는 하나의 특성을 하나의 컬럼으로 생성\n",
    "#값의 종류가 15가지이면 15개의 컬럼을 생성\n",
    "# (solution) 컬럼은 1개만 만들고 0부터 일련번호 형태로 값을 설정\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "one_hot = LabelEncoder()\n",
    "print(one_hot.fit_transform(df['displacement']))\n",
    "print(one_hot.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순서가 있는 범주형 데이터 인코딩 - Ordinal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Score\n",
      "0     A\n",
      "1     B\n",
      "2     C\n",
      "3     D\n",
      "4     F\n",
      "  Score  encoder\n",
      "0     A      4.0\n",
      "1     B      3.0\n",
      "2     C      2.0\n",
      "3     D      1.0\n",
      "4     F      0.0\n",
      "[[3. 0.]\n",
      " [2. 2.]\n",
      " [0. 1.]\n",
      " [1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "#sklearn의 인코더들은 문자열을 기준으로 정렬을 한 후 수치를 부여. 원하는 수치값을 부여하는 것은 불가능\n",
    "#범주형 데이터에 원하는 수치값을 부여해서 인코딩 할 때는 replace 메소드나 OrdinalEncoder를 이용\n",
    "df = pd.DataFrame({\"Score\":['A','B','C','D','F']})\n",
    "print(df)\n",
    "\n",
    "#A:4.0, #B:3.0 #C:2.0 #D:1.0 #F : 0\n",
    "mapper = {'A':4.0,'B':3.0,'C':2.0,'D':1.0,'F':0}\n",
    "\n",
    "df['encoder'] = df['Score'].replace(mapper)\n",
    "print(df)\n",
    "\n",
    "\n",
    "#순서가 있는 범주형 인코딩\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "features = np.array([['서울',2],['부산',52],['경기',31],['대구',54]])\n",
    "\n",
    "#1. 객체를 생성하자\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "#2.객체에다가 데이터를 준다\n",
    "result = encoder.fit_transform(features)\n",
    "print(result) #1열은 가나다순 정렬. 2열은 숫자 정렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형 데이터에서 누락값 삭제 - 머신러닝 알고리즘 이용_최근이웃법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.K평균분류 패키지 import\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#훈련할 데이터 생성\n",
    "X = np.array([[0, 2.10, 14.1],[1,1.18,13.33],[0, 1.22,1.27],[1,-0.10,-14.45]])\n",
    "\n",
    "#NaN을 가진 데이터\n",
    "X_with_nan = np.array([[np.NaN,0.87,13.31],[np.NaN, -0.67, -0.22]])\n",
    "\n",
    "#2. 분류기를 생성 \n",
    "clf = KNeighborsClassifier(3,weights='distance')\n",
    "\n",
    "#3. 훈련할 데이터 할당 : 1번째 이후 전체 데이터를 가지고 0번째 데이터를 예측\n",
    "train_model = clf.fit(X[:,1:],X[:,0])\n",
    "\n",
    "#4. 데이터 예측\n",
    "imputed_values = train_model.predict(X_with_nan[:,1:]) #X_with_nan에 행 전체에 1열 이후로 값들을 기반으로 예측해라 \n",
    "imputed_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame결합 : merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      "id            10 non-null int64\n",
      "stock_name    10 non-null object\n",
      "value         10 non-null float64\n",
      "price         10 non-null int64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 448.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      "id      10 non-null int64\n",
      "name    10 non-null object\n",
      "eps     10 non-null float64\n",
      "bps     10 non-null int64\n",
      "per     10 non-null float64\n",
      "pbr     10 non-null float64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 608.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5 entries, 0 to 4\n",
      "Data columns (total 9 columns):\n",
      "id            5 non-null int64\n",
      "stock_name    5 non-null object\n",
      "value         5 non-null float64\n",
      "price         5 non-null int64\n",
      "name          5 non-null object\n",
      "eps           5 non-null float64\n",
      "bps           5 non-null int64\n",
      "per           5 non-null float64\n",
      "pbr           5 non-null float64\n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 400.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15 entries, 0 to 14\n",
      "Data columns (total 9 columns):\n",
      "id            15 non-null int64\n",
      "stock_name    10 non-null object\n",
      "value         10 non-null float64\n",
      "price         10 non-null float64\n",
      "name          10 non-null object\n",
      "eps           10 non-null float64\n",
      "bps           10 non-null float64\n",
      "per           10 non-null float64\n",
      "pbr           10 non-null float64\n",
      "dtypes: float64(6), int64(1), object(2)\n",
      "memory usage: 1.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#필요한 패키지들 가져오기 \n",
    "import numpy as np #수치연산, 선형대수, ndarray라는 자료 구조를 가진 패키지\n",
    "import pandas as pd #Series, DF 자료구조를 가진 패키지\n",
    "import seaborn as sns #샘플데이터와 시각화\n",
    "\n",
    "#1. 합쳐줄 파일들 불러오기\n",
    "price = pd.read_excel('./data/stock price.xlsx')\n",
    "price.info()\n",
    "valuation = pd.read_excel('./data/stock valuation.xlsx')\n",
    "valuation.info()\n",
    "\n",
    "#2. 두 DataFrame을 id 기준으로 결합하기\n",
    "merge_df = pd.merge(price,valuation) #두 DataFrame에 중복되는 column이 id이므로 매개변수로 두 DF를 때려넣으면 알아서 매핑해서 결합함\n",
    "merge_df.info()\n",
    "#둘다 10개씩인데 왜 merge결과는 5개인가?  inner join 개념이기 때문(양쪽에 다 있어야 merger가 됨)\n",
    "\n",
    "#3 outer join해보기 : 어느 한쪽에만 존재해도 join에 참여\n",
    "merge_outer = pd.merge(price,valuation, how='outer', on='id')\n",
    "merge_outer.info() #>> id가 15개로 바뀜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame결합 : join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10 entries, 128940 to 204210\n",
      "Data columns (total 3 columns):\n",
      "stock_name    10 non-null object\n",
      "value         10 non-null float64\n",
      "price         10 non-null int64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 320.0+ bytes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10 entries, 130960 to 207940\n",
      "Data columns (total 5 columns):\n",
      "name    10 non-null object\n",
      "eps     10 non-null float64\n",
      "bps     10 non-null int64\n",
      "per     10 non-null float64\n",
      "pbr     10 non-null float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 480.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_name</th>\n",
       "      <th>value</th>\n",
       "      <th>price</th>\n",
       "      <th>name</th>\n",
       "      <th>eps</th>\n",
       "      <th>bps</th>\n",
       "      <th>per</th>\n",
       "      <th>pbr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>128940</td>\n",
       "      <td>한미약품</td>\n",
       "      <td>59385.666667</td>\n",
       "      <td>421000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130960</td>\n",
       "      <td>CJ E&amp;M</td>\n",
       "      <td>58540.666667</td>\n",
       "      <td>98900</td>\n",
       "      <td>CJ E&amp;M</td>\n",
       "      <td>6301.333333</td>\n",
       "      <td>54068.0</td>\n",
       "      <td>15.695091</td>\n",
       "      <td>1.829178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138250</td>\n",
       "      <td>엔에스쇼핑</td>\n",
       "      <td>14558.666667</td>\n",
       "      <td>13200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139480</td>\n",
       "      <td>이마트</td>\n",
       "      <td>239230.833333</td>\n",
       "      <td>254500</td>\n",
       "      <td>이마트</td>\n",
       "      <td>18268.166667</td>\n",
       "      <td>295780.0</td>\n",
       "      <td>13.931338</td>\n",
       "      <td>0.860437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142280</td>\n",
       "      <td>녹십자엠에스</td>\n",
       "      <td>468.833333</td>\n",
       "      <td>10200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145990</td>\n",
       "      <td>삼양사</td>\n",
       "      <td>82750.000000</td>\n",
       "      <td>82000</td>\n",
       "      <td>삼양사</td>\n",
       "      <td>5741.000000</td>\n",
       "      <td>108090.0</td>\n",
       "      <td>14.283226</td>\n",
       "      <td>0.758627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185750</td>\n",
       "      <td>종근당</td>\n",
       "      <td>40293.666667</td>\n",
       "      <td>100500</td>\n",
       "      <td>종근당</td>\n",
       "      <td>3990.333333</td>\n",
       "      <td>40684.0</td>\n",
       "      <td>25.185866</td>\n",
       "      <td>2.470259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192400</td>\n",
       "      <td>쿠쿠홀딩스</td>\n",
       "      <td>179204.666667</td>\n",
       "      <td>177500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199800</td>\n",
       "      <td>툴젠</td>\n",
       "      <td>-2514.333333</td>\n",
       "      <td>115400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204210</td>\n",
       "      <td>모두투어리츠</td>\n",
       "      <td>3093.333333</td>\n",
       "      <td>3475</td>\n",
       "      <td>모두투어리츠</td>\n",
       "      <td>85.166667</td>\n",
       "      <td>5335.0</td>\n",
       "      <td>40.802348</td>\n",
       "      <td>0.651359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock_name          value   price    name           eps       bps  \\\n",
       "id                                                                         \n",
       "128940       한미약품   59385.666667  421000     NaN           NaN       NaN   \n",
       "130960     CJ E&M   58540.666667   98900  CJ E&M   6301.333333   54068.0   \n",
       "138250      엔에스쇼핑   14558.666667   13200     NaN           NaN       NaN   \n",
       "139480        이마트  239230.833333  254500     이마트  18268.166667  295780.0   \n",
       "142280     녹십자엠에스     468.833333   10200     NaN           NaN       NaN   \n",
       "145990        삼양사   82750.000000   82000     삼양사   5741.000000  108090.0   \n",
       "185750        종근당   40293.666667  100500     종근당   3990.333333   40684.0   \n",
       "192400      쿠쿠홀딩스  179204.666667  177500     NaN           NaN       NaN   \n",
       "199800         툴젠   -2514.333333  115400     NaN           NaN       NaN   \n",
       "204210     모두투어리츠    3093.333333    3475  모두투어리츠     85.166667    5335.0   \n",
       "\n",
       "              per       pbr  \n",
       "id                           \n",
       "128940        NaN       NaN  \n",
       "130960  15.695091  1.829178  \n",
       "138250        NaN       NaN  \n",
       "139480  13.931338  0.860437  \n",
       "142280        NaN       NaN  \n",
       "145990  14.283226  0.758627  \n",
       "185750  25.185866  2.470259  \n",
       "192400        NaN       NaN  \n",
       "199800        NaN       NaN  \n",
       "204210  40.802348  0.651359  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join을 쓰는 경우, 파일을 불러오는 단계에서 미리 index를 설정해버린다.\n",
    "price = pd.read_excel('./data/stock price.xlsx', index_col='id')\n",
    "valuation = pd.read_excel('./data/stock valuation.xlsx', index_col='id')\n",
    "price.info()\n",
    "valuation.info()\n",
    "\n",
    "stock_join = price.join(valuation)\n",
    "stock_join # price를 기준으로 valuation에도 있으면 join. 즉, valuation row는 안들어 갈 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame 결합 : concat(), append(), combine_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a    b\n",
      "1  a0  NaN\n",
      "2  a1  NaN\n",
      "3  a2  NaN\n",
      "2  a2   b2\n",
      "3  a3   b3\n",
      "4  a4   b4\n",
      "     a    a    b\n",
      "1   a0  NaN  NaN\n",
      "2   a1   a2   b2\n",
      "3   a2   a3   b3\n",
      "4  NaN   a4   b4\n",
      "    a   a   b\n",
      "2  a1  a2  b2\n",
      "3  a2  a3  b3\n",
      "    a    b\n",
      "1  a0  NaN\n",
      "2  a1  NaN\n",
      "3  a2  NaN\n",
      "2  a2   b2\n",
      "3  a3   b3\n",
      "4  a4   b4\n",
      "    a    b\n",
      "1  a0  NaN\n",
      "2  a1   b2\n",
      "3  a2   b3\n",
      "4  a4   b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "#concat? 열 또는 행 방향으로 DataFrame을 합쳐주는 함수\n",
    "df1 = pd.DataFrame({'a':['a0','a1','a2']}, index=[1,2,3])\n",
    "df2 = pd.DataFrame({'a':['a2','a3','a4'], 'b':['b2','b3','b4']}, index=[2,3,4])\n",
    "\n",
    "print(pd.concat([df1,df2],axis=0)) #열이 같다면 행으로 합쳐! \n",
    "print(pd.concat([df1,df2],axis=1)) #행이 같다면 열로 합쳐!\n",
    "print(pd.concat([df1,df2],axis=1, join='inner')) #행이 같다면 열로 합쳐! 근데 한쪽에만 있는것은 다 빼\n",
    "\n",
    "print(df1.append(df2)) #열이 같다면 행으로 무조건 합치기 \n",
    "print(df1.combine_first(df2)) #인덱스를 기준으로 합치는데 호출하는 쪽 데이터를 우선적용함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
